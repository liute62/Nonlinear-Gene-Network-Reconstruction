}
r<-rbind(r, c(epsilon, this, apply(rec,2,mean)[3]))
}
r<-r[-1,]
r
plot(r[,1], r[,2], xlab="noise SD/signal SD", ylab="adjusted Rand Index", type="l", col="red",ylim=c(0,1),lwd=2, main=paste("# clusters", n.grps,", n.depend", n.depend))
lines(r[,1], r[,3],col="green",lwd=2, lty=1)
lines(r[,1], r[,4],col="blue",lwd=2, lty=1)
lines(r[,1], r[,5],col="blue",lwd=2, lty=2)
lines(r[,1], r[,6],col="blue",lwd=2, lty=3)
lines(r[,1], r[,7],col="blue",lwd=2, lty=4)
lines(r[,1], r[,8],col="cyan",lwd=2, lty=1)
lines(r[,1], r[,9],col="yellow",lwd=2,lty=1)
}
}
}
View(this.name)
a<-load(simu epsilon 1 n.depend 0 grp size 100 min size ratio 1 n grps 10 .bin)
load(simu epsilon 1 n.depend 0 grp size 100 min size ratio 1 n grps 10 .bin)
a<-load("simu epsilon 1 n.depend 0 grp size 100 min size ratio 1 n grps 10 .bin")
View(a)
View(rec)
a<-load("simu epsilon 1 n.depend 0 grp size 100 min size ratio 1 n grps 10 .bin")
View(rec)
a<-load("simu epsilon 0.5 n.depend 0 grp size 100 min size ratio 1 n grps 10 .bin")
View(rec)
a<-load("simu epsilon 1 n.depend 0 grp size 100 min size ratio 1 n grps 10 .bin")
View(rec)
setwd("/Users/liuhaodong1/simu")
source("clusGap.R")
source("DCOL_Kmeans.R")
############# the function to conduct simulation for one scenario
# epsilon: noise level
# n.depend: data generation dependence structure. can be 0, 1, 2
# n.samples: the number of columns of the matrix
# n.grps: the number of hidden clusters
# aver.grp.size: averge number of genes in a cluster
# n.fun.types: number of function types to use
# total.n: number of simulations
# min.size.ratio: to be passed to the dynamic tree cutting
one.simu<-function(epsilon, n.depend, n.samples=100, n.grps=10, aver.grp.size=100, n.fun.types=4, total.n=20, min.size.ratio)
{
library(nlnet3)
r<-rep(0,4)
for(N in 1:total.n)
{
n.genes<- (1+n.grps) * aver.grp.size
dataset=data.gen(n.genes, n.samples, n.grps, aver.grp.size, n.fun.types, epsilon, n.depend)
if (0 %in% unique(dataset$grps))
{
ngrp = length(unique(dataset$grps))-1
}
else
{
ngrp = length(unique(dataset$grps))
}
#print(dataset)
results<-data.cluster.2(dataset$data, ngrp, 100)$cluster
#print(results)
nlnet.mul<-nlnet(dataset$data,gene.community.method="multilevel",plot.method="none",gene.fdr.cutoff=0.5)$membership
#print(nlnet.mul)
nlnet.label<-nlnet(dataset$data,gene.community.method="label.propagation",plot.method="none",gene.fdr.cutoff=0.3)$membership
#print(nlnet.label)
nlnet.leading<-nlnet(dataset$data,gene.community.method="leading.eigenvector",plot.method="none",gene.fdr.cutoff=0.4)$membership
#print(nlnet.leading)
processable<-"haha"
hc= nlhc(dataset$data)
hgrps<-cutreeDynamic(hc, minClusterSize= aver.grp.size*min.size.ratio)
processable<-try(hgrps2<-cutree(hc, h=-2))
#print(results)
print(hgrps)
print(hgrps2)
print(adjustedRandIndex(dataset$grps + 1, hgrps))
print(adjustedRandIndex(dataset$grps + 1, hgrps2))
if(substr(processable,1,5)=="Error")
{
r<-rbind(r,c(
adjustedRandIndex(dataset$grps +1 , results+1),
adjustedRandIndex(dataset$grps + 1, hgrps),
NA,
adjustedRandIndex(dataset$grps +1 , nlnet.mul),
adjustedRandIndex(dataset$grps +1 , nlnet.label),
adjustedRandIndex(dataset$grps +1 , nlnet.leading)))
}else{
r<-rbind(r,c(
adjustedRandIndex(dataset$grps +1 , results+1),
adjustedRandIndex(dataset$grps + 1, hgrps),
adjustedRandIndex(dataset$grps + 1, hgrps2),
adjustedRandIndex(dataset$grps +1 , nlnet.mul),
adjustedRandIndex(dataset$grps +1 , nlnet.label),
adjustedRandIndex(dataset$grps +1 , nlnet.leading)))
}
}
print("end")
r<-r[-1,]
r
}
############# actual simulation
#all.epsilon<-c(1.2, 1.6, 2)
#all.n.depend<-c(0,1,2)
#all.grp.size<-c(100)
#min.size.ratio<-c(0.5, 0.7, 0.9, 1)
#n.grps<-c(10, 20)
all.epsilon<-c(0.5,1.0)
all.n.depend<-0
all.grp.size<-100
min.size.ratio<-1
n.grps<-10
combos<-expand.grid(all.epsilon, all.n.depend,all.grp.size,min.size.ratio, n.grps)
#combos
#foreach(m=nrow(combos):1) %dopar%
for(m in 1:nrow(combos))
{
#rec<-one.simu(epsilon=epsilon, n.depend=n.depend, aver.grp.size=grp.size, min.size.ratio=min.size.ratio, n.grps=n.grps, n.fun.types=4, total.n=2)
rec<-one.simu(epsilon=combos[m,1], n.depend=combos[m,2], aver.grp.size=combos[m,3], min.size.ratio=combos[m,4], n.grps=combos[m,5], n.fun.types=4, total.n=10)
print(rec)
#save(rec, file=paste("simu epsilon",epsilon, "n.depend", n.depend, "grp size",grp.size, "min size ratio",min.size.ratio," n grps",n.grps,".bin"))
save(rec, file=paste("simu epsilon", combos[m,1], "n.depend", combos[m,2],"grp size",combos[m,3], "min size ratio", combos[m,4], "n grps", combos[m,5], ".bin"))
}
library(nlnet3)
library(nlnet3)
library(nlnet3)
library(nlnet3)
setwd("/Users/liuhaodong1/simu")
source("clusGap.R")
source("DCOL_Kmeans.R")
############# the function to conduct simulation for one scenario
# epsilon: noise level
# n.depend: data generation dependence structure. can be 0, 1, 2
# n.samples: the number of columns of the matrix
# n.grps: the number of hidden clusters
# aver.grp.size: averge number of genes in a cluster
# n.fun.types: number of function types to use
# total.n: number of simulations
# min.size.ratio: to be passed to the dynamic tree cutting
one.simu<-function(epsilon, n.depend, n.samples=100, n.grps=10, aver.grp.size=100, n.fun.types=4, total.n=20, min.size.ratio)
{
library(nlnet3)
r<-rep(0,4)
for(N in 1:total.n)
{
n.genes<- (1+n.grps) * aver.grp.size
dataset=data.gen(n.genes, n.samples, n.grps, aver.grp.size, n.fun.types, epsilon, n.depend)
setwd("/Users/liuhaodong1/simu")
source("clusGap.R")
source("DCOL_Kmeans.R")
############# the function to conduct simulation for one scenario
# epsilon: noise level
# n.depend: data generation dependence structure. can be 0, 1, 2
# n.samples: the number of columns of the matrix
# n.grps: the number of hidden clusters
# aver.grp.size: averge number of genes in a cluster
# n.fun.types: number of function types to use
# total.n: number of simulations
# min.size.ratio: to be passed to the dynamic tree cutting
one.simu<-function(module.size, epsilon, n.depend, n.samples=100, n.grps=10, aver.grp.size=100, n.fun.types=4, total.n=20, min.size.ratio)
{
library(nlnet3)
r<-rep(0,4)
for(N in 1:total.n)
{
n.genes<- (1+n.grps) * aver.grp.size
dataset=data.gen(n.genes, n.samples, n.grps, aver.grp.size, n.fun.types, epsilon, n.depend)
if (0 %in% unique(dataset$grps))
{
ngrp = length(unique(dataset$grps))-1
}
else
{
ngrp = length(unique(dataset$grps))
}
#print(dataset)
results<-data.cluster.2(dataset$data, ngrp, 100)$cluster
#print(results)
nlnet.mul<-nlnet(min.module.size=module.size,dataset$data,gene.community.method="multilevel",plot.method="none",gene.fdr.cutoff=0.1)$membership
#print(nlnet.mul)
nlnet.label<-nlnet(min.module.size=module.size,dataset$data,gene.community.method="label.propagation",plot.method="none",gene.fdr.cutoff=0.1)$membership
#print(nlnet.label)
nlnet.leading<-nlnet(min.module.size=module.size,dataset$data,gene.community.method="leading.eigenvector",plot.method="none",gene.fdr.cutoff=0.1)$membership
#print(nlnet.leading)
processable<-"haha"
hc= nlhc(dataset$data)
hgrps<-cutreeDynamic(hc, minClusterSize= aver.grp.size*min.size.ratio)
processable<-try(hgrps2<-cutree(hc, h=-2))
#print(results)
print(hgrps)
print(hgrps2)
print(adjustedRandIndex(dataset$grps + 1, hgrps))
print(adjustedRandIndex(dataset$grps + 1, hgrps2))
if(substr(processable,1,5)=="Error")
{
r<-rbind(r,c(
adjustedRandIndex(dataset$grps +1 , results+1),
adjustedRandIndex(dataset$grps + 1, hgrps),
NA,
adjustedRandIndex(dataset$grps +1 , nlnet.mul),
adjustedRandIndex(dataset$grps +1 , nlnet.label),
adjustedRandIndex(dataset$grps +1 , nlnet.leading)))
}else{
r<-rbind(r,c(
adjustedRandIndex(dataset$grps +1 , results+1),
adjustedRandIndex(dataset$grps + 1, hgrps),
adjustedRandIndex(dataset$grps + 1, hgrps2),
adjustedRandIndex(dataset$grps +1 , nlnet.mul),
adjustedRandIndex(dataset$grps +1 , nlnet.label),
adjustedRandIndex(dataset$grps +1 , nlnet.leading)))
}
}
print("end")
r<-r[-1,]
r
}
############# actual simulation
#all.epsilon<-c(1.2, 1.6, 2)
#all.n.depend<-c(0,1,2)
#all.grp.size<-c(100)
#min.size.ratio<-c(0.5, 0.7, 0.9, 1)
#n.grps<-c(10, 20)
all.module.size<-c(10,20)
all.epsilon<-c(0.5,1.0)
all.n.depend<-0
all.grp.size<-100
min.size.ratio<-1
n.grps<-10
combos<-expand.grid(all.epsilon, all.n.depend,all.grp.size,min.size.ratio, n.grps,all.module.size)
#combos
#foreach(m=nrow(combos):1) %dopar%
for(m in 1:nrow(combos))
{
#rec<-one.simu(epsilon=epsilon, n.depend=n.depend, aver.grp.size=grp.size, min.size.ratio=min.size.ratio, n.grps=n.grps, n.fun.types=4, total.n=2)
rec<-one.simu(module.size=combos[m,6],epsilon=combos[m,1], n.depend=combos[m,2], aver.grp.size=combos[m,3], min.size.ratio=combos[m,4], n.grps=combos[m,5], n.fun.types=4, total.n=10)
print(rec)
#save(rec, file=paste("simu epsilon",epsilon, "n.depend", n.depend, "grp size",grp.size, "min size ratio",min.size.ratio," n grps",n.grps,".bin"))
save(rec, file=paste("simu epsilon", combos[m,1], "n.depend", combos[m,2],"grp size",combos[m,3], "min size ratio", combos[m,4], "n grps", combos[m,5], ".bin"))
}
#}
############# plotting results
par(mfcol=c(2,3))
for(grp.size in c(100))
{
#for(n.depend in c(0,1,2))
for(n.depend in c(0))
{
#for(n.grps in c(10, 20))
for(n.grps in c(10))
{
r<-rep(NA,8)
#for(epsilon in c(0.2, 0.6, 0.8, 1.2, 1.6))
for(epsilon in c(0.5,1.0))
{
#for(min.size.ratio in c(0.5, 0.7, 0.9, 1))
for(min.size.ratio in c(1))
{
#this.name<-paste("linear simu epsilon", epsilon, "n.depend", n.depend,"grp size",grp.size, "min size ratio", min.size.ratio, "n grps", n.grps, ".bin")
this.name<-paste("simu epsilon",epsilon, "n.depend", n.depend, "grp size",grp.size, "min size ratio",min.size.ratio,"n grps", n.grps,".bin")
load(this.name)
#load("simu epsilon 1.2 n.depend 2 grp size 10 min size ratio 1 n grps 20.bin")
if(epsilon == 0.5){
this<-apply(rec,2,mean)[c(1,4,2)]
}else{
this<-c(this, apply(rec,2,mean)[2])
}
{
r
}
############# actual simulation
#all.epsilon<-c(1.2, 1.6, 2)
}
print("end")
r<-r[-1,]
r
}
############# actual simulation
}
}
print("end")
r<-r[-1,]
r
}
############# actual simulation
# n.fun.types: number of function types to use
# total.n: number of simulations
# min.size.ratio: to be passed to the dynamic tree cutting
one.simu<-function(module.size, epsilon, n.depend, n.samples=100, n.grps=10, aver.grp.size=100, n.fun.types=4, total.n=20, min.size.ratio)
{
library(nlnet3)
r<-rep(0,4)
setwd("/Users/liuhaodong1/simu")
source("clusGap.R")
source("DCOL_Kmeans.R")
############# the function to conduct simulation for one scenario
# epsilon: noise level
# n.depend: data generation dependence structure. can be 0, 1, 2
# n.samples: the number of columns of the matrix
# n.grps: the number of hidden clusters
# aver.grp.size: averge number of genes in a cluster
# n.fun.types: number of function types to use
# total.n: number of simulations
# min.size.ratio: to be passed to the dynamic tree cutting
one.simu<-function(module.size, epsilon, n.depend, n.samples=100, n.grps=10, aver.grp.size=100, n.fun.types=4, total.n=20, min.size.ratio)
{
library(nlnet3)
r<-rep(0,4)
for(N in 1:total.n)
{
n.genes<- (1+n.grps) * aver.grp.size
dataset=data.gen(n.genes, n.samples, n.grps, aver.grp.size, n.fun.types, epsilon, n.depend)
if (0 %in% unique(dataset$grps))
{
ngrp = length(unique(dataset$grps))-1
}
else
{
ngrp = length(unique(dataset$grps))
}
#print(dataset)
results<-data.cluster.2(dataset$data, ngrp, 100)$cluster
#print(results)
nlnet.mul<-nlnet(min.module.size=module.size,dataset$data,gene.community.method="multilevel",plot.method="none",gene.fdr.cutoff=0.1)$membership
#print(nlnet.mul)
nlnet.label<-nlnet(min.module.size=module.size,dataset$data,gene.community.method="label.propagation",plot.method="none",gene.fdr.cutoff=0.1)$membership
#print(nlnet.label)
nlnet.leading<-nlnet(min.module.size=module.size,dataset$data,gene.community.method="leading.eigenvector",plot.method="none",gene.fdr.cutoff=0.1)$membership
#print(nlnet.leading)
processable<-"haha"
hc= nlhc(dataset$data)
hgrps<-cutreeDynamic(hc, minClusterSize= aver.grp.size*min.size.ratio)
processable<-try(hgrps2<-cutree(hc, h=-2))
#print(results)
print(hgrps)
print(hgrps2)
print(adjustedRandIndex(dataset$grps + 1, hgrps))
print(adjustedRandIndex(dataset$grps + 1, hgrps2))
if(substr(processable,1,5)=="Error")
{
r<-rbind(r,c(
adjustedRandIndex(dataset$grps +1 , results+1),
adjustedRandIndex(dataset$grps + 1, hgrps),
NA,
adjustedRandIndex(dataset$grps +1 , nlnet.mul),
adjustedRandIndex(dataset$grps +1 , nlnet.label),
adjustedRandIndex(dataset$grps +1 , nlnet.leading)))
}else{
r<-rbind(r,c(
adjustedRandIndex(dataset$grps +1 , results+1),
adjustedRandIndex(dataset$grps + 1, hgrps),
adjustedRandIndex(dataset$grps + 1, hgrps2),
adjustedRandIndex(dataset$grps +1 , nlnet.mul),
adjustedRandIndex(dataset$grps +1 , nlnet.label),
adjustedRandIndex(dataset$grps +1 , nlnet.leading)))
}
}
print("end")
r<-r[-1,]
r
}
############# actual simulation
#all.epsilon<-c(1.2, 1.6, 2)
#all.n.depend<-c(0,1,2)
#all.grp.size<-c(100)
#min.size.ratio<-c(0.5, 0.7, 0.9, 1)
#n.grps<-c(10, 20)
all.module.size<-c(10,20)
all.epsilon<-c(0.5,1.0)
all.n.depend<-0
all.grp.size<-100
min.size.ratio<-1
n.grps<-10
combos<-expand.grid(all.epsilon, all.n.depend,all.grp.size,min.size.ratio, n.grps,all.module.size)
#combos
#foreach(m=nrow(combos):1) %dopar%
for(m in 1:nrow(combos))
{
#rec<-one.simu(epsilon=epsilon, n.depend=n.depend, aver.grp.size=grp.size, min.size.ratio=min.size.ratio, n.grps=n.grps, n.fun.types=4, total.n=2)
rec<-one.simu(module.size=combos[m,6],epsilon=combos[m,1], n.depend=combos[m,2], aver.grp.size=combos[m,3], min.size.ratio=combos[m,4], n.grps=combos[m,5], n.fun.types=4, total.n=10)
print(rec)
#save(rec, file=paste("simu epsilon",epsilon, "n.depend", n.depend, "grp size",grp.size, "min size ratio",min.size.ratio," n grps",n.grps,".bin"))
save(rec, file=paste("simu epsilon", combos[m,1], "n.depend", combos[m,2],"grp size",combos[m,3], "min size ratio", combos[m,4], "n grps", combos[m,5], ".bin"))
}
source('~/simu/simu.R')
source('~/simu/simu.R')
View(combos)
View(combos)
View(combos)
View(combos)
library(fdrtool)
library(igraph)
setwd("/Users/liuhaodong1/Desktop")
load("test_data_low noise.bin")
gene.community.method<-"multilevel"
#gene.community.method<-"label.propagation"
#gene.community.method<-"leading.eigenvector"
gene.fdr.cutoff<-0.05
module.min.size<-40
#input<-a$data
#input<-input[1:1000,]
library(nlnet3)
input<-data.gen(1000,100,10,100)
grp<-input$grp
grp
library(fdrtool)
library(igraph)
setwd("/Users/liuhaodong1/Desktop")
load("test_data_low noise.bin")
gene.community.method<-"multilevel"
#gene.community.method<-"label.propagation"
#gene.community.method<-"leading.eigenvector"
gene.fdr.cutoff<-0.05
module.min.size<-40
#input<-a$data
#input<-input[1:1000,]
library(nlnet3)
input<-data.gen(1000,100,10,100)
grp<-input$grp
grp
input<-input$data
n<-nrow(input)
m<-ncol(input)
normrow<-function(array)
{
m<-apply(array,1,mean,na.rm=T)
s<-apply(array,1,sd,na.rm=T)
array<-(array-m)/s
return(array)
}
gene.specific.null<-function(array, B=500)
{
null.mat<-matrix(0, nrow=nrow(array), ncol=B)
l<-ncol(array)
normrow<-function(array)
{
m<-apply(array,1,mean,na.rm=T)
s<-apply(array,1,sd,na.rm=T)
array<-(array-m)/s
return(array)
}
gene.specific.null<-function(array, B=500)
{
null.mat<-matrix(0, nrow=nrow(array), ncol=B)
l<-ncol(array)
d.array<-array[,1:(l-1)]
for(i in 1:B)
{
this.order<-sample(l, l, replace=FALSE)
for(j in 1:(l-1)) d.array[,j]<-abs(array[,this.order[j+1]]-array[,this.order[j]])
null.mat[,i]<-apply(d.array, 1, sum)
}
r<-cbind(apply(null.mat, 1, mean), apply(null.mat, 1, sd))
return(r)
}
scol.matrix.order<-function(array,x) # x is the vector, a is the matrix, find ordered distance of rows.of.a|x
{
if(is.null(nrow(array)) | nrow(array) == 1)
{
array<-as.vector(array)
array<-array[order(x)]
d<-array[2:length(array)]-array[1:(length(array)-1)]
dd<-sum(abs(d),na.rm=T)
}else{
array<-array[,order(x)]
d<-array[,2:ncol(array)]-array[,1:(ncol(array)-1)]
dd<-apply(abs(d),1,sum,na.rm=T)
}
return(dd)
}
scol.matrix<-function(a, direction=2)  # when direction is 1, scol.matrix[i,j] = SCOL(a[i,], a[j,]), j|i
{
rdmat<-matrix(0, ncol=nrow(a), nrow=nrow(a))
for(j in 1:nrow(a))
{
rdmat[j,]<-scol.matrix.order(a, a[j,])
}
if(direction == 2)
{
rdmat.diff<-rdmat-t(rdmat)
sel<-which(rdmat.diff > 0)
rdmat[sel]<-t(rdmat)[sel]
}
return(rdmat)
}
gene.specific.p<-function(null.distr, new.d)
{
for(i in 1:length(new.d))
{
new.d[i]<-pnorm(new.d[i], mean=null.distr[i,1], sd=null.distr[i,2], lower.tail=TRUE)
}
return(new.d)
}
gene.specific.q<-function(new.d)
{
for(i in 1:length(new.d))
{
new.d[i]<-qnorm(new.d[i], mean=0, sd=1, lower.tail=TRUE)
}
return(new.d)
}
library(fdrtool)
library(igraph)
setwd("/Users/liuhaodong1/Desktop")
load("test_data_low noise.bin")
gene.community.method<-"multilevel"
#gene.community.method<-"label.propagation"
#gene.community.method<-"leading.eigenvector"
gene.fdr.cutoff<-0.05
module.min.size<-40
#input<-a$data
#input<-input[1:1000,]
library(nlnet3)
input<-data.gen(1000,100,10,100)
grp<-input$grp
grp
input<-input$data
